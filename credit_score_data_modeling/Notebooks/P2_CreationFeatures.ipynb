{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementation of a scoring model**\n",
    "## **Notebook 2/6 - Creation of features & Data assembly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is organized as follows:\n",
    "\n",
    "**0. Set up**\n",
    "- 0.1 Loading libraries and useful functions\n",
    "- 0.2 Loading and description of the dataset\n",
    "    \n",
    "**1. Creation of features & Data assembly**\n",
    "- 1.1 APP_TRAIN data\n",
    "- 1.2 BUREAU data\n",
    "- 1.3 BUREAU_BALANCE data\n",
    "- 1.4 PREVIOUS APPLICATION data\n",
    "- 1.5 CASH Data\n",
    "- 1.6 CREDIT CARD Data\n",
    "- 1.7 PAYMENT Data\n",
    "\n",
    "**2. Handling of anomalies**\n",
    "        \n",
    "**3. Data encoding**\n",
    "\n",
    "**4. Data export**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 0. SETUP\n",
    "\n",
    "In this first step, the working framework is put in place, that is to say:\n",
    "- The necessary Python libraries and packages are loaded\n",
    "- Useful functions are defined\n",
    "- The dataset is loaded\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.1 LOADING LIBRARIES AND USEFUL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"./Resources/functions\")\n",
    "\n",
    "import helper_functions as hf\n",
    "import graphical_functions as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.2 LOADING AND DESCRIPTION OF THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app_train = pd.read_csv(\"./Resources/datasets/origin/application_train.csv\")\n",
    "\n",
    "bureau_balance = pd.read_csv(\"./Resources/datasets/origin/bureau_balance.csv\")\n",
    "\n",
    "bureau = pd.read_csv(\"./Resources/datasets/origin/bureau.csv\")\n",
    "\n",
    "credit = pd.read_csv(\"./Resources/datasets/origin/credit_card_balance.csv\")\n",
    "\n",
    "installments = pd.read_csv(\"./Resources/datasets/origin/installments_payments.csv\")\n",
    "\n",
    "cash = pd.read_csv(\"./Resources/datasets/origin/POS_CASH_balance.csv\")\n",
    "\n",
    "prev_app = pd.read_csv(\"./Resources/datasets/origin/previous_application.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 1. CREATION OF FEATURES & ASSEMBLY OF DATA\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.1 APP_TRAIN DATA\n",
    "\n",
    "Creation of a business feature: \n",
    "- The ratio of initial contribution compared to the price of the property\n",
    "- The annuity/income ratio \n",
    "- The job seniority/age ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self financed on goods price ratio (%)\n",
    "app_train[\"SELF_FINANCED_PERCENT\"] = (app_train[\"AMT_GOODS_PRICE\"] - app_train[\"AMT_CREDIT\"])/app_train[\"AMT_GOODS_PRICE\"]*100\n",
    "app_train[\"SELF_FINANCED_PERCENT\"] = app_train[\"SELF_FINANCED_PERCENT\"].map(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANNUITY ON INCOME ratio (%)\n",
    "app_train[\"ANNUITY_ON_INCOME\"] = app_train[\"AMT_ANNUITY\"] / app_train[\"AMT_INCOME_TOTAL\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Days employed on age ratio (%)\n",
    "app_train['DAYS_EMPLOYED_PERCENT'] = app_train['DAYS_EMPLOYED'] / app_train['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.2 BUREAU DATA\n",
    "\n",
    "Creation of the following features:\n",
    "- Number of previous bank loans\n",
    "\n",
    "Creation of the following features per loan per customer:\n",
    "- For each qualitative feature:\n",
    "    - number\n",
    "    - average\n",
    "    - sum\n",
    "- For each quantitative feature: \n",
    "    - number\n",
    "    - average\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.23 gb.\n",
      "New Memory Usage: 0.1 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types for less memory usage\n",
    "bureau = hf.convert_types(bureau, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation previous_loan_counts\n",
    "previous_loan_counts = bureau.groupby('SK_ID_CURR', \n",
    "                                      as_index=False)['SK_ID_BUREAU']\\\n",
    "                             .count()\\\n",
    "                             .rename(columns = {'SK_ID_BUREAU':\\\n",
    "                                                'previous_loan_counts'})\n",
    "\n",
    "# Merge previous_loan_counts with train on SK_ID_CURR, left\n",
    "app_train = app_train.merge(previous_loan_counts, \n",
    "                            on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# fillna(0) with train\n",
    "app_train['previous_loan_counts'] = app_train['previous_loan_counts']\\\n",
    "                                    .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of bureau_counts containing for each possible value \n",
    "# of the qualitative features 2 new feature : count and \n",
    "# normalized count\n",
    "\n",
    "bureau_counts = hf.agg_categorical(bureau, \n",
    "                                     group_var = 'SK_ID_CURR', \n",
    "                                     df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of bureau_agg containing for each possible value\n",
    "# of the quantitative features 5 new features : count, max,\n",
    "# mean, min and sum\n",
    " \n",
    "bureau_agg = hf.agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), \n",
    "                            group_var = 'SK_ID_CURR', \n",
    "                            df_name = 'bureau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Insert computed features into training data\n",
    "\n",
    "# Merge bureau_counts with app_train\n",
    "app_train = app_train.merge(bureau_counts, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Merge bureau_agg with app_train\n",
    "app_train = app_train.merge(bureau_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Deleting missing columns\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.3 BUREAU_BALANCE DATA\n",
    "\n",
    "Creation of the following features per loan per customer:\n",
    "- For each qualitative feature:\n",
    "    - number\n",
    "    - average\n",
    "    - sum\n",
    "- Mathematical features for each quantitative feature per loan per customer: \n",
    "    - number\n",
    "    - average\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.66 gb.\n",
      "New Memory Usage: 0.25 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types for less memory usage\n",
    "bureau_balance = hf.convert_types(bureau_balance, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Counts of each type of status for each previous loan\n",
    "bureau_balance_counts = hf.agg_categorical(bureau_balance, \n",
    "                                           group_var = 'SK_ID_BUREAU', \n",
    "                                           df_name = 'bureau_balance')\n",
    "\n",
    "# Creation bureau_balance_agg \n",
    "# Calculate value count statistics for each `SK_ID_CURR` \n",
    "bureau_balance_agg = hf.agg_numeric(bureau_balance, \n",
    "                                    group_var = 'SK_ID_BUREAU', \n",
    "                                    df_name = 'bureau_balance')\n",
    "\n",
    "# Creation bureau_by_loan\n",
    "# Dataframe grouped by the loan\n",
    "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, \n",
    "                                          right_index = True, \n",
    "                                          left_on = 'SK_ID_BUREAU', \n",
    "                                          how = 'outer')\n",
    "\n",
    "# Merge to include the SK_ID_CURR - Possibly several rows per client\n",
    "bureau_by_loan = bureau_by_loan.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], \n",
    "                                      on = 'SK_ID_BUREAU', \n",
    "                                      how = 'left')\n",
    "\n",
    "# Creation bureau_balance_by_client - One row per client\n",
    "bureau_balance_by_client = hf.agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), \n",
    "                                          group_var = 'SK_ID_CURR', \n",
    "                                          df_name = 'client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Merge bureau_balance_by_client with app_train\n",
    "app_train = app_train.merge(bureau_balance_by_client, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Deleting missing columns\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.4 PREVIOUS APPLICATION DATA\n",
    "\n",
    "Creation of the following features:\n",
    "- Mathematical features for each qualitative feature per client: \n",
    "    - sum\n",
    "    - number\n",
    "    - average\n",
    "- Mathematical features for each quantitative feature per client: \n",
    "    - number\n",
    "    - average\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.49 gb.\n",
      "New Memory Usage: 0.16 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types from previous\n",
    "prev_app = hf.convert_types(prev_app, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation previous_agg\n",
    "prev_agg = hf.agg_numeric(prev_app, 'SK_ID_CURR', 'previous')\n",
    "\n",
    "# Creation previous_counts\n",
    "prev_counts = hf.agg_categorical(prev_app, 'SK_ID_CURR', 'previous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Merge previous_counts with app_train\n",
    "app_train = app_train.merge(prev_counts, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Merge previous_agg with app_train\n",
    "app_train = app_train.merge(prev_agg, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Deleting missing columns\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.5 CASH DATA\n",
    "\n",
    "Creation of the following features:\n",
    "- Mathematical features for each qualitative feature per client: \n",
    "    - sum\n",
    "    - number\n",
    "    - average\n",
    "- Mathematical features for each quantitative feature per client: \n",
    "    - number\n",
    "    - average\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.64 gb.\n",
      "New Memory Usage: 0.29 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert types of cash\n",
    "cash = hf.convert_types(cash, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Creation cash_by_client\n",
    "cash_by_client = hf.aggregate_client(cash, \n",
    "                                     group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                     df_names = ['cash', 'client'])\n",
    "\n",
    "# Merge cash_by_client with app_train\n",
    "app_train = app_train.merge(cash_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "\n",
    "# Deleting missing columns\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.6 CREDIT CARD DATA\n",
    "\n",
    "Creation of the following features:\n",
    "- Mathematical features for each qualitative feature per client: \n",
    "    - sum\n",
    "    - number\n",
    "    - average\n",
    "- Mathematical features for each quantitative feature per client: \n",
    "    - number\n",
    "    - average\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.71 gb.\n",
      "New Memory Usage: 0.34 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert credit types\n",
    "credit = hf.convert_types(credit, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Creation credit_by_client\n",
    "credit_by_client = hf.aggregate_client(credit, \n",
    "                                       group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                       df_names = ['credit', 'client'])\n",
    "\n",
    "# Merge credit_by_client with app_train\n",
    "app_train = app_train.merge(credit_by_client, on=\"SK_ID_CURR\", how=\"left\")\n",
    "\n",
    "# Deleting missing columns\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.7 PAYMENT DATA\n",
    "\n",
    "Creation of the following features:\n",
    "- Mathematical features for each qualitative feature per client: \n",
    "    - sum\n",
    "    - number\n",
    "    - average\n",
    "- Mathematical features for each quantitative feature per client: \n",
    "    - number\n",
    "    - average\n",
    "    - maximum\n",
    "    - minimum\n",
    "    - sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Memory Usage: 0.87 gb.\n",
      "New Memory Usage: 0.44 gb.\n"
     ]
    }
   ],
   "source": [
    "# Convert installment types\n",
    "installments = hf.convert_types(installments, print_info = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 columns with greater than 90% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Creation installments_by_clients\n",
    "installments_by_client = hf.aggregate_client(installments, \n",
    "                                             group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], \n",
    "                                             df_names = ['installments', 'client'])\n",
    "\n",
    "# Merge installments_by_clietns with app_train\n",
    "app_train = app_train.merge(installments_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Deleting missing columns\n",
    "app_train = hf.remove_missing_columns(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 2. PROCESSING ANOMALIES\n",
    "\n",
    "The exploratory analysis revealed an identical anomaly for 18% of clients: a length of service of 365,000 days. \n",
    "\n",
    "We will replace this abnormal value with NaN, while retaining the information that these clients had this anomaly.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an anomalous flag column\n",
    "app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace the anomalous values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 3. DATA ENCODING\n",
    "\n",
    "Transformation of qualitative variables into quantitative variables via the use of:\n",
    "- label encoding for qualitative variables with less than 2 modalities\n",
    "- one hot encoding for other qualitative variables\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            # Train on the data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            \n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 4. DATA EXPORT\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.to_csv(\"./Resources/datasets/assembled/full_training_data.csv\", index=False, chunksize=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
