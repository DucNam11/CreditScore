{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Implementation of a scoring model**\n",
    "## **Notebook 4/6 - Modeling: Selection of features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is organized as follows:\n",
    "\n",
    "**0. Set up**\n",
    "- 0.1 Loading libraries and useful functions\n",
    "- 0.2 Loading and description of the dataset\n",
    "- 0.3 Removal of irrelevant features\n",
    "- 0.4 Data separation\n",
    "    \n",
    "**1. Feature selection**\n",
    "- 1.1 Baseline: no selection\n",
    "- 1.2 Removal of collinear features\n",
    "- 1.3 Deletion of features with more than 75% missing values\n",
    "- 1.4 Deletion of features having zero importance for the model\n",
    "- 1.5 Deletion of features having an importance less than 95% for the model\n",
    "- 1.6 Performance comparison\n",
    "\n",
    "**2. Conclusion**\n",
    "\n",
    "**3. Data export**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 0. SETUP\n",
    "\n",
    "In this first step, the working framework is put in place, that is to say:\n",
    "- The necessary Python libraries and packages are loaded\n",
    "- Useful functions are defined\n",
    "- The dataset is loaded\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.1 LOADING LIBRARIES AND USEFUL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import time\n",
    "import random\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgb\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\"./Resources/functions\")\n",
    "\n",
    "import helper_functions as hf\n",
    "import graphical_functions as gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.2 LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Resources/datasets/assembled/full_training_data.csv\").rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.3 REMOVAL OF IRRELEVANT FEATURES\n",
    "\n",
    "We will remove the column indicating the customer ID.\n",
    "\n",
    "In addition, to avoid perpetuating bias, we will remove the column relating to the gender of clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"SK_ID_CURR\", \"CODE_GENDER_M\", \"CODE_GENDER_F\", \"CODE_GENDER_XNA\"]\n",
    "data_model = data.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 0.4 DATA SEPARATION\n",
    "\n",
    "The dataset will be separated into training data and test data.\n",
    "\n",
    "The exploratory analysis having revealed a significant imbalance of classes in TARGET, we must ensure to maintain these proportions in our new games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_model.drop(columns=[\"TARGET\"]), \n",
    "                                                    data_model[\"TARGET\"], \n",
    "                                                    train_size=0.8, random_state=42, \n",
    "                                                    stratify=data_model[\"TARGET\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 1. SELECTION OF FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_score = make_scorer(hf.bank_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=[\"Features\", \"Custom Score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.1 BASELINE: NO SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                                    objective = 'binary', \n",
    "                                    class_weight = 'balanced', \n",
    "                                    learning_rate = 0.05, \n",
    "                                    reg_alpha = 0.1, \n",
    "                                    reg_lambda = 0.1, \n",
    "                                    subsample = 0.8, \n",
    "                                    n_jobs = -1, \n",
    "                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.fit(X_train, y_train, eval_metric=custom_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[len(results)] = [\"All features\", \n",
    "                             round(hf.bank_score(y_test, y_pred), 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.2 REMOVAL OF COLINEAR FEATURES\n",
    "\n",
    "For each pair of features that are more than 90% collinear (Spearman coefficient), one of the 2 features is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.9\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = X_train.corr(\"spearman\").abs()\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d columns to remove.' % (len(to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nc = X_train.drop(columns = to_drop)\n",
    "X_test_nc = X_test.drop(columns = to_drop)\n",
    "\n",
    "print('Training shape: ', X_train_nc.shape)\n",
    "print('Testing shape: ', X_test_nc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_model.fit(X_train_nc, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nc_model.predict(X_test_nc)\n",
    "\n",
    "row = [\"Without collinear\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.3 DELETION OF FEATURES WITH MORE THAN 75% MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train missing values (in percent)\n",
    "X_train_collinear_missing = (X_train_nc.isnull().sum() / len(X_train_nc)).sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_collinear_missing = X_train_collinear_missing.index[X_train_collinear_missing > THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_without_collinear_missing = X_train_nc.drop(columns= X_train_collinear_missing)\n",
    "X_test_without_collinear_missing = X_test_nc.drop(columns= X_train_collinear_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncm_model.fit(X_train_without_collinear_missing, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ncm_model.predict(X_test_without_collinear_missing)\n",
    "\n",
    "row = [\"Without collinear and missing\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.4 DELETION OF FEATURES OF ZERO IMPORTANCE FOR THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = X_train_without_collinear_missing\n",
    "test = X_test_without_collinear_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty array to hold feature importances\n",
    "feature_importances = np.zeros(train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnof_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model twice to avoid overfitting\n",
    "for i in range(2):\n",
    "    \n",
    "    # Train using early stopping\n",
    "    ncmnof_model.fit(train, \n",
    "              y_train, \n",
    "              eval_metric = custom_score)\n",
    "    \n",
    "    # Record the feature importances\n",
    "    feature_importances += ncmnof_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average feature importances\n",
    "feature_importances = feature_importances / 2\n",
    "feature_importances = pd.DataFrame({'feature': list(train.columns), \n",
    "                                    'importance': feature_importances}).sort_values('importance', ascending = False)\n",
    "\n",
    "feature_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the features with zero importance\n",
    "zero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])\n",
    "print('There are %d features with 0.0 importance' % len(zero_features))\n",
    "feature_importances.tail(len(zero_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature_importances = gf.plot_feature_importances2(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = zero_features)\n",
    "test = test.drop(columns = zero_features)\n",
    "\n",
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_round_zero_features, feature_importances = hf.identify_zero_importance_features(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature_importances = gf.plot_feature_importances2(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=second_round_zero_features)\n",
    "test = test.drop(columns=second_round_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training shape: ', train.shape)\n",
    "print('Testing shape: ', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_round_zero_features, feature_importances = hf.identify_zero_importance_features(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_feature_importances = gf.plot_feature_importances2(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnof_model.fit(train, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = ncmnof_model.predict(test)\n",
    "\n",
    "row = [\"Without all + 0 importance features\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.5 DELETION OF FEATURES HAVING AN IMPORTANCE LESS THAN 95% FOR THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for cumulative importance\n",
    "THRESHOLD = 0.95\n",
    "\n",
    "# Extract the features to keep\n",
    "features_to_keep = list(norm_feature_importances[norm_feature_importances['cumulative_importance'] < THRESHOLD]['feature'])\n",
    "\n",
    "# Create new datasets with smaller features\n",
    "train_small = train[features_to_keep]\n",
    "test_small = test[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnofif_model = lgb.LGBMClassifier(n_estimators=10000, \n",
    "                              objective = 'binary', \n",
    "                              class_weight = 'balanced', \n",
    "                              learning_rate = 0.05, \n",
    "                              reg_alpha = 0.1, \n",
    "                              reg_lambda = 0.1, \n",
    "                              subsample = 0.8, \n",
    "                              n_jobs = -1, \n",
    "                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncmnofif_model.fit(train_small, \n",
    "          y_train, \n",
    "          eval_metric = custom_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = ncmnofif_model.predict(test_small)\n",
    "\n",
    "row = [\"Without 0 importance features and small\", \n",
    "       hf.bank_score(y_test, y_pred)]\n",
    "\n",
    "results.loc[len(results)] = row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 1.6 PERFORMANCE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score is obtained by removing:\n",
    "- collinear features\n",
    "- features with more than 75% missing values\n",
    "- features having 0 importance for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ncmnof_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 2.CONCLUSION\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, our model has the following characteristics: \n",
    "- algorithm: Light Gradient Boosting Machine\n",
    "- rebalancing strategy: class_weight = 'balanced'\n",
    "- features: selected in this notebook\n",
    "\n",
    "Our model obtains a score of 0.109, or 10.9% better than the baseline consisting of systematically predicting that the customer will repay their credit.\n",
    "\n",
    "In order to finalize our model and improve its performance, the last step consists of optimizing the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 3. DATA EXPORT\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model and the dataset to save time\n",
    "dump(best_model, \"lgbm_best_features_model.joblib\")\n",
    "train.to_csv(\"./Resources/datasets/assembled/train.csv\")\n",
    "y_train.to_csv(\"./Resources/datasets/assembled/y_train.csv\")\n",
    "test.to_csv(\"./Resources/datasets/assembled/test.csv\") \n",
    "y_test.to_csv(\"./Resources/datasets/assembled/y_test.csv\")\n",
    "\n",
    "# Saving columns for new data pipeline\n",
    "dump(train.columns, \"model_features.joblib\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
